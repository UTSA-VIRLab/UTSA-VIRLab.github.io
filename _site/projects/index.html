<!DOCTYPE html>
<html lang="en" data-dark="false">
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!--
  put your analytics (e.g. Google Analytics) tracking code here
-->

  <!--
  put your search engine verification (e.g. Google Search Console) tag here
-->

  


























<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Projects | VIR Lab</title>

<link rel="icon" href="/images/icon.png">

<meta name="title" content="Projects">
<meta name="description" content="CS@UTSA. An easy-to-use, flexible website template for labs, with automatic citations, GitHub tag imports, pre-built components, and more.">

<meta property="og:title" content="Projects">
<meta property="og:site_title" content="VIR Lab">
<meta property="og:description" content="CS@UTSA. An easy-to-use, flexible website template for labs, with automatic citations, GitHub tag imports, pre-built components, and more.">
<meta property="og:url" content="http://localhost:4000">
<meta property="og:image" content="/images/share.jpg">
<meta property="og:locale" content="en_US">

<meta property="twitter:title" content="Projects">
<meta property="twitter:description" content="CS@UTSA. An easy-to-use, flexible website template for labs, with automatic citations, GitHub tag imports, pre-built components, and more.">
<meta property="twitter:url" content="http://localhost:4000">
<meta property="twitter:card" content="summary_large_image">
<meta property="twitter:image" content="/images/share.jpg">


  <meta property="og:type" content="website">


<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "WebSite",
    
    "name": "Projects",
    "description": "CS@UTSA. An easy-to-use, flexible website template for labs, with automatic citations, GitHub tag imports, pre-built components, and more.",
    "headline": "Projects",
    "publisher": {
      "@type": "Organization",
      "logo": { "@type": "ImageObject", "url": "/images/icon.png" }
    },
    "url": "http://localhost:4000"
  }
</script>

<link rel="alternate" type="application/rss+xml" href="http://localhost:4000/feed.xml">

  <!-- Google Fonts -->
<!-- automatically get url from fonts used in theme file -->

<link rel="preconnect" href="https://fonts.gstatic.com">
<link href="https://fonts.googleapis.com/css2?display=swap&&family=Barlow:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600&amp;family=Roboto+Mono:ital,wght@0,200;0,400;0,500;0,600;1,200;1,400;1,500;1,600" rel="stylesheet">

<!-- Font Awesome icons (load asynchronously due to size) -->

<link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet" media="none" onload="this.removeAttribute('media'); this.onload = null;">
<noscript>
  <link href="https://use.fontawesome.com/releases/v6.5.0/css/all.css" rel="stylesheet">
</noscript>

  <!-- third party styles -->
<!-- https://stylishthemes.github.io/Syntax-Themes/pygments/ -->
<link href="https://cdn.jsdelivr.net/gh/StylishThemes/Syntax-Themes/pygments/css-github/pygments-tomorrow-night-eighties.css" rel="stylesheet">

<!-- include all sass in styles folder -->


  
    <link href="/_styles/-theme.css" rel="stylesheet">
  

  
    <link href="/_styles/alert.css" rel="stylesheet">
  

  
    <link href="/_styles/all.css" rel="stylesheet">
  

  
    <link href="/_styles/anchor.css" rel="stylesheet">
  

  
    <link href="/_styles/background.css" rel="stylesheet">
  

  
    <link href="/_styles/body.css" rel="stylesheet">
  

  
    <link href="/_styles/bold.css" rel="stylesheet">
  

  
    <link href="/_styles/button.css" rel="stylesheet">
  

  
    <link href="/_styles/card.css" rel="stylesheet">
  

  
    <link href="/_styles/checkbox.css" rel="stylesheet">
  

  
    <link href="/_styles/citation.css" rel="stylesheet">
  

  
    <link href="/_styles/code.css" rel="stylesheet">
  

  
    <link href="/_styles/cols.css" rel="stylesheet">
  

  
    <link href="/_styles/dark-toggle.css" rel="stylesheet">
  

  
    <link href="/_styles/details.css" rel="stylesheet">
  

  
    <link href="/_styles/feature.css" rel="stylesheet">
  

  
    <link href="/_styles/figure.css" rel="stylesheet">
  

  
    <link href="/_styles/float.css" rel="stylesheet">
  

  
    <link href="/_styles/font.css" rel="stylesheet">
  

  
    <link href="/_styles/footer.css" rel="stylesheet">
  

  
    <link href="/_styles/form.css" rel="stylesheet">
  

  
    <link href="/_styles/grid.css" rel="stylesheet">
  

  
    <link href="/_styles/header.css" rel="stylesheet">
  

  
    <link href="/_styles/heading.css" rel="stylesheet">
  

  
    <link href="/_styles/highlight.css" rel="stylesheet">
  

  
    <link href="/_styles/icon.css" rel="stylesheet">
  

  
    <link href="/_styles/image.css" rel="stylesheet">
  

  
    <link href="/_styles/link.css" rel="stylesheet">
  

  
    <link href="/_styles/list.css" rel="stylesheet">
  

  
    <link href="/_styles/main.css" rel="stylesheet">
  

  
    <link href="/_styles/paragraph.css" rel="stylesheet">
  

  
    <link href="/_styles/portrait.css" rel="stylesheet">
  

  
    <link href="/_styles/post-excerpt.css" rel="stylesheet">
  

  
    <link href="/_styles/post-info.css" rel="stylesheet">
  

  
    <link href="/_styles/post-nav.css" rel="stylesheet">
  

  
    <link href="/_styles/quote.css" rel="stylesheet">
  

  
    <link href="/_styles/rule.css" rel="stylesheet">
  

  
    <link href="/_styles/search-box.css" rel="stylesheet">
  

  
    <link href="/_styles/search-info.css" rel="stylesheet">
  

  
    <link href="/_styles/section.css" rel="stylesheet">
  

  
    <link href="/_styles/table.css" rel="stylesheet">
  

  
    <link href="/_styles/tags.css" rel="stylesheet">
  

  
    <link href="/_styles/textbox.css" rel="stylesheet">
  

  
    <link href="/_styles/tooltip.css" rel="stylesheet">
  

  
    <link href="/_styles/util.css" rel="stylesheet">
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  


<!-- include all css in styles folder -->



  <!-- third party scripts -->
<script src="https://unpkg.com/@popperjs/core@2" defer></script>
<script src="https://unpkg.com/tippy.js@6" defer></script>
<script src="https://unpkg.com/mark.js@8" defer></script>

<!-- include all js in scripts folder -->


  <script src="/_scripts/anchors.js"></script>

  <script src="/_scripts/dark-mode.js"></script>

  <script src="/_scripts/fetch-tags.js"></script>

  <script src="/_scripts/search.js"></script>

  <script src="/_scripts/site-search.js"></script>

  <script src="/_scripts/table-wrap.js"></script>

  <script src="/_scripts/tooltip.js"></script>


</head>

  <body>
    







<header class="background" style="--image: url('/images/background.jpg')" data-dark="true">
  <a href="/" class="home">
    
      <span class="logo">
        
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="-40 -60 80 100">
  <style>
    .bubble {
      animation: float 2s ease-out both infinite var(--delay);
    }
    @keyframes float {
      0% {
        opacity: 0;
      }
      50% {
        transform: translateY(0);
        opacity: 0;
      }
      75% {
        opacity: 1;
      }
      100% {
        opacity: 0;
        transform: translateY(-40px);
      }
    }
  </style>
  <g fill="currentColor" opacity="0.5">
    <circle class="bubble" cx="0" cy="-10" r="3" style="--delay: 0.1s"></circle>
    <circle class="bubble" cx="0" cy="-10" r="3" style="--delay: 0.4s"></circle>
    <circle class="bubble" cx="0" cy="-10" r="3" style="--delay: 1.1s"></circle>
  </g>
  <path fill="#38bdf8" d="
      M 0 -22.5
      L -19.5 -11.25
      L -19.5 11.25
      L 0 22.5
      L 19.5 11.25
      L 19.5 -11.25
      z
    "></path>
  <path fill="#bae6fd" d="
      M 0 -22.5
      L -19.5 -11.25
      L 0 0
      L 19.5 -11.25
      z
    "></path>
  <path fill="none" stroke="currentColor" stroke-width="5" d="
      M -18 -53
      L -10 -53
      L -10 -29.2
      L -30.3 -17.5
      L -30.3 17.5
      L 0 35
      L 30.3 17.5
      L 30.3 -17.5
      L 10 -29.2
      L 10 -53
      L 18 -53
    "></path>
</svg>

        
      </span>
    
    
      <span class="title-text" data-tooltip="Home">
        
          <span class="title">VIR Lab</span>
        
        
          <span class="subtitle">CS@UTSA</span>
        
      </span>
    
  </a>

  <input class="nav-toggle" type="checkbox" aria-label="show/hide nav">

  <nav>
    
    
      
        <a href="/research/" data-tooltip="Published works">
          Research
        </a>
      
    
      
        <a href="/projects/" data-tooltip="Software, datasets, and more">
          Projects
        </a>
      
    
      
        <a href="/team/" data-tooltip="About our team">
          Team
        </a>
      
    
      
        <a href="/blog/" data-tooltip="Musings and miscellany">
          Blog
        </a>
      
    
      
        <a href="/contact/" data-tooltip="Email, address, and location">
          Contact
        </a>
      
    
  </nav>
</header>

    <main>
      <!--
  modify main content of page:
  - add section breaks
  - attach section properties
  - filter out blank sections
-->






  
  
  

  <section class="background" data-size="28px">
    <!-- Inline CSS to override parent centering, set full-width cards, and style the modal -->
<style>
  /* Override any inherited centering */
  .background, .background *, .feature, .feature * {
    text-align: left !important;
  }
  /* Ensure project cards span full width */
  .card {
    width: 100% !important;
    margin: 0 auto 20px auto !important;
  }
  /* Modal styling */
  .modal {
    display: none;
    position: fixed;
    z-index: 1000;
    left: 0;
    top: 0;
    width: 100%;
    height: 100%;
    overflow: auto;
    background-color: rgba(0,0,0,0.5);
  }
  .modal-content {
    background-color: #fff;
    margin: 10% auto;
    padding: 20px;
    border: 1px solid #888;
    width: 80%;
    max-width: 600px;
  }
  .close {
    color: #aaa;
    float: right;
    font-size: 28px;
    font-weight: bold;
    cursor: pointer;
  }
  .close:hover {
    color: black;
  }
</style>

<h2 id="current-projects">Current Projects</h2>

<div class="card" style="width: 100%; text-align: left;" data-style="">
  <!-- Removed image block -->

  <div class="card-text" style="text-align: left;">
    
    <a href="https://github.com/" class="card-title" style="display: block; text-align: left;">
      HCC: Small: Making Virtual Reality Safe
    </a>
    

    
    <span class="card-agency" style="display: block; text-align: left;">
    <strong>Agency:</strong> NSF - (CISE) Core Programs
  </span>
    

    
    <span class="card-award" style="display: block; text-align: left;">
    <strong>Award:</strong> $600,000
  </span>
    

    
    <span class="card-investigator" style="display: block; text-align: left;">
    <strong>Investigator:</strong> John Quarles, Kevin Desai
  </span>
    

    
    <!-- Button to trigger a popup modal with the description -->
    <button class="show-description" data-description="Although consumer-level virtual reality head-mounted displays have become affordable enough for a broad user base to purchase, there are still serious concerns about safety. Head-mounted displays block out the surrounding real world, which can hide obstacles, such as tables, pets, walls, or other potential collision hazards. Current approaches to avoiding collisions depend on the user to define play area boundaries; this process is subject to user error and thus can lead to injury. Moreover, current approaches are ineffective for games that require fast motions, as the systems may not react in time to prevent injury. To address these problems, the investigators will create camera-based methods for detecting potential collisions in real time and evaluate feedback techniques to reduce the incidence of injury when using virtual reality headsets. This approach has the potential to make the use of virtual reality much safer in real-world environments. The objective of this project is to create and evaluate reconstruction, segmentation, and motion-prediction techniques to inform obstacle avoidance feedback and reduce the incidence of injury to people using virtual reality head mounted displays. Providing feedback tailored to the specific locations of the user’s body that are in proximity to real obstacles will, ideally, reduce user collisions with real-world objects compared to prior approaches. Specifically, the team will 1) determine the best approaches to real obstacle detection and segmentation, 2) investigate the efficacy of full body motion prediction approaches, 3) ascertain the optimal modality and locations of real obstacle alerts to maximize presence while minimizing collisions, and 4) evaluate the longitudinal impact of real obstacle alert systems in virtual reality systems. Ultimately, this research will result in human motion datasets that can be used for future motion prediction in virtual reality research, as well as open-source plugins that will make current virtual reality experiences safer by reducing injuries.
" style="display: block; text-align: left;">
      Show Description
    </button>
    


  </div>
</div>

<div class="card" style="width: 100%; text-align: left;" data-style="">
  <!-- Removed image block -->

  <div class="card-text" style="text-align: left;">
    
    <a href="https://github.com/" class="card-title" style="display: block; text-align: left;">
      Collaborative Research: HCC: Medium: HCI in Motion -- Using EEG, Eye Tracking, and Body Sensing for Attention-Aware Mobile Mixed Reality
    </a>
    

    
    <span class="card-agency" style="display: block; text-align: left;">
    <strong>Agency:</strong> NSF - (CISE) Core Programs
  </span>
    

    
    <span class="card-award" style="display: block; text-align: left;">
    <strong>Award:</strong> $457,105
  </span>
    

    
    <span class="card-investigator" style="display: block; text-align: left;">
    <strong>Investigator:</strong> John Quarles, Kevin Desai
  </span>
    

    
    <!-- Button to trigger a popup modal with the description -->
    <button class="show-description" data-description="Mobile, wireless, headsets for virtual and augmented reality, such as the Meta Quest 2 and Microsoft HoloLens-2, are becoming more widely used in many applications beyond video games, such as training, construction, and medicine. However, wearing these head-worn goggles while walking can make some people feel sick or distracted, which has even led to injury in some cases. This effect is similar to texting while walking, but potentially worse because a person’s entire periphery can be filled with distracting media elements. While previous research has investigated these issues when users are standing still or seated, it is unclear how problems unfold and how they can be prevented while users are in motion. Specifically, this project will investigate how and why virtual and augmented reality headsets affect attention and feelings of sickness. First, this work will record data, such as heart rate, brain waves, and the direction users are turning their eyes to, while they are wearing virtual and augmented reality headsets and walking. Secondly, this project will develop ways to reduce sickness and distraction while walking with virtual and augmented reality headsets. This work will improve the safety of mobile virtual and augmented reality headsets, products that virtually all big technology companies today heavily invest in as possible companions or replacements to smartphones. This project will be introduced in courses and research mentorship projects at The University of Texas at San Antonio and the University of California at Santa Barbara, to advance research training of both undergraduate and graduate students. Considering that both universities and research teams have a history of supporting many underrepresented minority students, it is expected that the educational value of this project will be high, especially in terms of recruiting and mentoring women and underrepresented minority students. There is an increasing prevalence of mobile, immersive interfaces (e.g., mobile Virtual Reality(VR) / Augmented Reality (AR)) that may affect users’ cognitive capacities and situational awareness, potentially leading to physical harm (e.g., impaired task performance, tripping over physical obstacles in VR, unsafe street crossings while seeing advertisements in AR). The landscape of human-computer interaction has expanded from fairly well standardized stationary office configurations to more varied mobile and immersive settings involving active body movements (mobile and situated computing, AR, mobile VR) and simulated first-person perspective changes and motion experiences (immersive computing). To make matters worse, compared to more standardized platforms such as desktop and laptop UIs, tablet and smartphone interfaces, individual differences among users have a much bigger usability impact in context-driven surround-focus usage scenarios found in mobile AR/VR. For example, motion sickness (i.e., cybersickness) in VR is known to inflict symptoms of widely varying severity, depending on the individual user. One serious consequence is that interaction designers have difficulties providing engaging general experiences that are universally usable by a wide variety of users. Despite the increasing prevalence of immersive technologies and their pitfalls, the precise cognitive and physiological mechanisms at play when ‘computing in motion’ are not well understood. This work is aimed at filling this knowledge gap. The specific objectives are: 1) to assess the cognitive effects of interacting with mobile AR/VR while users are walking, 2) to provide automated tools to effectively reduce the cognitive demand of mobile AR/VR, and 3) to make mobile AR/VR safer and more usable. Based on preliminary data, the central hypothesis is that through multi-modal sensing combined with machine learning approaches, mobile AR/VR applications can learn the characteristics of user behavior and provide real time adaptations that will reduce user error, increase ease of use, improve task performance, and reduce the impact of physical hazards. This work will improve the safety of mobile AR and mobile VR, paradigms that virtually all big technology companies today heavily invest in as a possible follow-up paradigm to the smartphone platform. Educational impact will occur through incorporation of research outcomes into undergraduate and graduate courses offered at The University of Texas at San Antonio and the University of California at Santa Barbara, and research training and mentorship opportunities for both undergraduate and graduate students. The courses include Machine Learning, Deep Learning for Visual Computing, Human-Computer Interaction, and Mobile Application Programming. Because our project integrates a topic of high social impact with cutting edge machine learning and human-computer interaction research along with proven successful mentorship strategies, the educational impacts of the project will be high, especially in terms of recruiting and mentoring women and underrepresented minority students.
" style="display: block; text-align: left;">
      Show Description
    </button>
    


  </div>
</div>

<div class="card" style="width: 100%; text-align: left;" data-style="">
  <!-- Removed image block -->

  <div class="card-text" style="text-align: left;">
    
    <a href="https://github.com/" class="card-title" style="display: block; text-align: left;">
      CRII: HCC: 3D Hand &amp; Full-Body Pose Estimation in Telehealth for Children with Autism
    </a>
    

    
    <span class="card-agency" style="display: block; text-align: left;">
    <strong>Agency:</strong> NSF - (CISE) Research Initiation Initiative (CRII) 2021
  </span>
    

    
    <span class="card-award" style="display: block; text-align: left;">
    <strong>Award:</strong> $174,368
  </span>
    

    
    <span class="card-investigator" style="display: block; text-align: left;">
    <strong>Investigator:</strong> Kevin Desai
  </span>
    

    
    <!-- Button to trigger a popup modal with the description -->
    <button class="show-description" data-description="This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2). The overall objective of this project is to provide efficient full-body interaction in virtual reality systems that do not use head-mounted displays. This project aims to create accurate and real-time 3D hand and body pose estimation, in the highly significant application area of children with autism. A novel synthetic hand data generation framework will generate 3D hand poses with increased diversity in terms of hand distance from camera, hand size, camera viewpoint, occlusion, background, and skin color. The outcome will be a novel 3D synthetic hand dataset consisting of realistic and kinematically accurate hand models with articulated poses that will advance current and future research endeavors in 3D hand pose estimation research. The project will advance the state-of-the-art in 3D body pose estimation for humans present further away from the camera at room-scale distances. The synthetic dataset, algorithms, and programming libraries will be made publicly available for wide-spread adoption, thereby advancing pose estimation research. This research will have broad societal impact because it will improve the usability and interaction in human centered telehealth applications, initially helping with the applied behavior analysis for children with autism. Existing systems that employ head-mounted displays or wearable sensors for tracking the user’s hand and body movements are not suitable for children with autism, and have disadvantages in many other application areas. Therefore, by enabling 3D hand and full-body pose estimation, this project will advance a plethora of 3D immersive applications such as education, virtual STEM laboratories, tele-rehabilitation, tele-operation, military training, entertainment, and communication. The need for real-time, remote and interactive human motion sensing exists now more than ever, considering the increase in virtual activities because of the recent pandemic.
" style="display: block; text-align: left;">
      Show Description
    </button>
    


  </div>
</div>

<div class="card" style="width: 100%; text-align: left;" data-style="">
  <!-- Removed image block -->

  <div class="card-text" style="text-align: left;">
    
    <a href="https://github.com/" class="card-title" style="display: block; text-align: left;">
       Electronic Health Record Big Data and Radiomic Analytics for Precision Medicine Approach to Long-COVID
    </a>
    

    
    <span class="card-agency" style="display: block; text-align: left;">
    <strong>Agency:</strong> San Antonio Partnership for Precision Therapeutics (SAPPT)
  </span>
    

    
    <span class="card-award" style="display: block; text-align: left;">
    <strong>Award:</strong> $50,000
  </span>
    

    
    <span class="card-investigator" style="display: block; text-align: left;">
    <strong>Investigator:</strong> Dhireesha Kudithipudi, Kevin Desai, Anandi Dutta
  </span>
    

    


  </div>
</div>
  </section>

  
  
  

  <section class="background" data-size="page">
    <!--
  background: ;
  dark: ;
  size: ;
-->

<h2 id="past-projects">Past Projects</h2>

<!-- Remove style="small" so that the full card template is used -->

<div class="card" style="width: 100%; text-align: left;" data-style="">
  <!-- Removed image block -->

  <div class="card-text" style="text-align: left;">
    
    <a href="https://github.com/" class="card-title" style="display: block; text-align: left;">
       A step towards smart and connected health in behavior analysis
    </a>
    

    
    <span class="card-agency" style="display: block; text-align: left;">
    <strong>Agency:</strong> UTSA VPR Office - GREAT 2021
  </span>
    

    
    <span class="card-award" style="display: block; text-align: left;">
    <strong>Award:</strong> $20,000
  </span>
    

    
    <span class="card-investigator" style="display: block; text-align: left;">
    <strong>Investigator:</strong> Leslie Neely, Peyman Najafirad, Qian Chen, Kevin Desai
  </span>
    

    


  </div>
</div>

<div class="card" style="width: 100%; text-align: left;" data-style="">
  <!-- Removed image block -->

  <div class="card-text" style="text-align: left;">
    
    <a href="https://github.com/" class="card-title" style="display: block; text-align: left;">
       Project Lovelace 2.0: Advancing Women in AI Career Pathways
    </a>
    

    
    <span class="card-agency" style="display: block; text-align: left;">
    <strong>Agency:</strong> Xilinx Inc. WIT University Grants 2021
  </span>
    

    
    <span class="card-award" style="display: block; text-align: left;">
    <strong>Award:</strong> $30,000
  </span>
    

    
    <span class="card-investigator" style="display: block; text-align: left;">
    <strong>Investigator:</strong> Dhireesha Kudithipudi, Amina Qutub, Kevin Desai
  </span>
    

    


  </div>
</div>

<!-- Modal Popup Markup for full description -->
<div id="descriptionModal" class="modal">
  <div class="modal-content">
    <span class="close">×</span>
    <div id="modalDescriptionContent"></div>
  </div>
</div>

<!-- JavaScript to handle the modal popup -->
<script>
  document.addEventListener("DOMContentLoaded", function() {
    var modal = document.getElementById("descriptionModal");
    var modalContent = document.getElementById("modalDescriptionContent");
    var closeBtn = document.querySelector(".modal .close");

    // Close modal when clicking on the close button
    closeBtn.onclick = function() {
      modal.style.display = "none";
    };

    // Close modal when clicking outside the modal content
    window.onclick = function(event) {
      if (event.target == modal) {
        modal.style.display = "none";
      }
    };

    // Attach click event listeners to all "Show More" buttons
    var buttons = document.querySelectorAll(".show-description");
    buttons.forEach(function(button) {
      button.addEventListener("click", function() {
        var description = this.getAttribute("data-description");
        modalContent.innerHTML = description;
        modal.style.display = "block";
      });
    });
  });
</script>
  </section>


    </main>
    


<footer class="background" style="--image: url('/images/background.jpg')" data-dark="true" data-size="wide">
  <!--
    <div>
      Extra details like contact info or address
    </div>
  -->

  <div>
    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="mailto:contact@your-lab.com" data-tooltip="Email" data-style="bare" aria-label="Email">
      <i class="icon fa-solid fa-envelope"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://orcid.org/0000-0001-8713-9213" data-tooltip="ORCID" data-style="bare" aria-label="ORCID">
      <i class="icon fa-brands fa-orcid"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://scholar.google.com/citations?user=ZzaTdlYAAAAJ&hl" data-tooltip="Google Scholar" data-style="bare" aria-label="Google Scholar">
      <i class="icon fa-brands fa-google"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://github.com/your-lab" data-tooltip="GitHub" data-style="bare" aria-label="GitHub">
      <i class="icon fa-brands fa-github"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://twitter.com/YourLabHandle" data-tooltip="Twitter" data-style="bare" aria-label="Twitter">
      <i class="icon fa-brands fa-twitter"></i>
      
    </a>
  </div>


    
      
      
      



  <div class="button-wrapper">
    <a class="button" href="https://youtube.com/YourLabChannel" data-tooltip="YouTube" data-style="bare" aria-label="YouTube">
      <i class="icon fa-brands fa-youtube"></i>
      
    </a>
  </div>


    
  </div>

  <div>
    © 2025
    VIR Lab
      |   Built with
    <a href="https://github.com/greenelab/lab-website-template">
      Lab Website Template
    </a>
  </div>

  <input type="checkbox" class="dark-toggle" data-tooltip="Dark mode" aria-label="toggle dark mode" oninput="onDarkToggleChange(event)">
</footer>

  </body>
</html>
